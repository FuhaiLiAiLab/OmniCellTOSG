{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fdb0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Parquet: ./cell_metadata.parquet\n",
      "Saved: ./field_uniques\\cell_type_unique_values.csv\n",
      "Saved: ./field_uniques\\tissue_general_unique_values.csv\n",
      "Saved: ./field_uniques\\tissue_unique_values.csv\n",
      "Saved: ./field_uniques\\disease_unique_values.csv\n",
      "Saved: ./field_uniques\\development_stage_unique_values.csv\n",
      "Saved: ./field_uniques\\sex_unique_values.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "INPUT_PARQUET = \"./cell_metadata.parquet\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"./field_uniques\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Fields to process\n",
    "FIELDS = [\"cell_type\", \"tissue_general\", \"tissue\", \"disease\", \"development_stage\", \"sex\"]\n",
    "\n",
    "\n",
    "print(f\"Loading from Parquet: {INPUT_PARQUET}\")\n",
    "df = pd.read_parquet(INPUT_PARQUET)\n",
    "\n",
    "# Generate one CSV per field\n",
    "for field in FIELDS:\n",
    "    if field in df.columns:\n",
    "        unique_values = df[field].dropna().unique()\n",
    "        unique_values.sort()\n",
    "        output_path = os.path.join(OUTPUT_DIR, f\"{field}_unique_values.csv\")\n",
    "        pd.Series(unique_values, name=field).to_csv(output_path, index=False)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "    else:\n",
    "        print(f\"Field not found in data: {field}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1abaa7",
   "metadata": {},
   "source": [
    "## Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f81594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched results saved to: ./mapping_table/mapped_diseases.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Paths\n",
    "UNIQUE_DISEASE_PATH = \"./field_uniques/disease_unique_values.csv\"\n",
    "BMG_DISEASE_PATH = \"../BMG/BioMedGraphica_Disease.csv\"\n",
    "OUTPUT_PATH = \"./mapping_table/mapped_diseases.json\"\n",
    "\n",
    "# Custom match anchors\n",
    "MATCH_ANCHORS = {\n",
    "    \"Mild cognitive impairment\": \"cognitive impairment with or without cerebellar ataxia\",\n",
    "    \"Mixed gliomas\": \"glioma\",\n",
    "}\n",
    "\n",
    "# Terms to skip matching (non-disease labels)\n",
    "SKIP_MATCHING_TERMS = {\n",
    "    \"healthy\", \"normal\", \"unclassified\", \"control\", \"none\", \"no disease\",\n",
    "    \"cell stress\", \"b-cell non-hodgkin lymphoma\"\n",
    "}\n",
    "\n",
    "# Specific normalization for skip-matched terms\n",
    "NORMALIZED_SKIP_MATCHES = {\n",
    "    \"healthy\": \"normal\",\n",
    "    \"control\": \"normal\",\n",
    "    \"none\": \"normal\",\n",
    "    \"no disease\": \"normal\"\n",
    "}\n",
    "\n",
    "# Load input data\n",
    "unique_diseases = pd.read_csv(UNIQUE_DISEASE_PATH).dropna()[[\"disease\"]].squeeze().tolist()\n",
    "bmg_df = pd.read_csv(BMG_DISEASE_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "# Build candidate map from BMG\n",
    "candidate_map = []\n",
    "for _, row in bmg_df.iterrows():\n",
    "    bmg_id = row[\"BioMedGraphica_ID\"]\n",
    "    for col in row.index:\n",
    "        if col == \"BioMedGraphica_ID\":\n",
    "            continue\n",
    "        values = str(row[col]).split(\";\") if \";\" in str(row[col]) else [row[col]]\n",
    "        for val in values:\n",
    "            val_clean = val.strip()\n",
    "            if val_clean:\n",
    "                candidate_map.append((val_clean, bmg_id, col))\n",
    "\n",
    "all_terms = [entry[0] for entry in candidate_map]\n",
    "\n",
    "# Match loop\n",
    "results = []\n",
    "for disease in unique_diseases:\n",
    "    disease_lower = disease.lower().strip()\n",
    "\n",
    "    # Rule-based normalization\n",
    "    if disease_lower in NORMALIZED_SKIP_MATCHES:\n",
    "        standardized_term = NORMALIZED_SKIP_MATCHES[disease_lower]\n",
    "        results.append({\n",
    "            \"original_disease\": disease,\n",
    "            \"query_used\": disease,\n",
    "            \"matched_term\": standardized_term,\n",
    "            \"matched_field\": \"standardized\",\n",
    "            \"BioMedGraphica_ID\": None,\n",
    "            \"match_score\": None\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Skip matching but use original term\n",
    "    if disease_lower in SKIP_MATCHING_TERMS:\n",
    "        results.append({\n",
    "            \"original_disease\": disease,\n",
    "            \"query_used\": disease,\n",
    "            \"matched_term\": disease,\n",
    "            \"matched_field\": \"NA\",\n",
    "            \"BioMedGraphica_ID\": None,\n",
    "            \"match_score\": None\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    query_term = MATCH_ANCHORS.get(disease, disease)\n",
    "\n",
    "    # Try exact match first\n",
    "    matched_exact = None\n",
    "    for i, term in enumerate(all_terms):\n",
    "        if query_term.lower() == term.lower():\n",
    "            matched_exact = candidate_map[i]\n",
    "            score = 100\n",
    "            break\n",
    "\n",
    "    if matched_exact:\n",
    "        matched_term, matched_bmg_id, matched_field = matched_exact\n",
    "    else:\n",
    "        match, score, idx = process.extractOne(\n",
    "            query=query_term,\n",
    "            choices=all_terms,\n",
    "            scorer=fuzz.token_sort_ratio\n",
    "        )\n",
    "        matched_term, matched_bmg_id, matched_field = candidate_map[idx]\n",
    "\n",
    "    results.append({\n",
    "        \"original_disease\": disease,\n",
    "        \"query_used\": query_term,\n",
    "        \"matched_term\": matched_term,\n",
    "        \"matched_field\": matched_field,\n",
    "        \"BioMedGraphica_ID\": matched_bmg_id,\n",
    "        \"match_score\": score\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "display_name_path = \"../BMG/BioMedGraphica_Disease_Display_Name.csv\"\n",
    "display_df = pd.read_csv(display_name_path, dtype=str).dropna(subset=[\"BioMedGraphica_ID\", \"BMG_Disease_Name\"])\n",
    "bmg_name_map = dict(zip(display_df[\"BioMedGraphica_ID\"], display_df[\"BMG_Disease_Name\"]))\n",
    "\n",
    "# Post-process: replace matched_term using display name if BioMedGraphica_ID is available\n",
    "for item in results:\n",
    "    bmg_id = item.get(\"BioMedGraphica_ID\")\n",
    "    if bmg_id and bmg_id in bmg_name_map:\n",
    "        item[\"matched_term\"] = bmg_name_map[bmg_id]\n",
    "\n",
    "# Save results\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Matched results saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7278ed15",
   "metadata": {},
   "source": [
    "## Cell Type Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7103b0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches: 756 / 809 (93.45%)\n",
      "Review-needed entries saved to: ./mapping_table/review_celltypes_score_not_100.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Paths\n",
    "UNIQUE_CELLTYPE_PATH = \"./field_uniques/cell_type_unique_values.csv\"\n",
    "BMG_CELLTYPE_PATH = \"../BMG/cell_type_mapping_table.csv\"\n",
    "OUTPUT_JSON = \"./mapping_table/mapped_celltypes.json\"\n",
    "OUTPUT_REVIEW = \"./mapping_table/review_celltypes_score_not_100.json\"\n",
    "\n",
    "# Custom match anchors (optional)\n",
    "MATCH_ANCHORS = {\n",
    "    \"Epithelial (malignant)\": \"Epithelial cell\",\n",
    "    \"Epithelial (non-malignant)\": \"Epithelial cell\",\n",
    "    \"Cancer-associated fibroblast\": \"fibroblast\",\n",
    "    \"Endocrine\": \"endocrine cell\",\n",
    "}\n",
    "\n",
    "# Terms to skip matching\n",
    "SKIP_MATCHING_TERMS = {\"unclassified\", \"unknown\", \"unannoted\"}\n",
    "\n",
    "# Load inputs\n",
    "unique_celltypes = pd.read_csv(UNIQUE_CELLTYPE_PATH).dropna()[[\"cell_type\"]].squeeze().tolist()\n",
    "bmg_df = pd.read_csv(BMG_CELLTYPE_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "# Build BMG match candidates\n",
    "candidate_map = []\n",
    "for _, row in bmg_df.iterrows():\n",
    "    bmg_id = row[\"CMT_ID\"]\n",
    "    for col in row.index:\n",
    "        if col == \"CMT_ID\":\n",
    "            continue\n",
    "        values = str(row[col]).split(\";\") if \";\" in str(row[col]) else [row[col]]\n",
    "        for val in values:\n",
    "            val_clean = val.strip()\n",
    "            if val_clean:\n",
    "                candidate_map.append((val_clean, bmg_id, col))\n",
    "\n",
    "all_terms = [entry[0] for entry in candidate_map]\n",
    "\n",
    "# Matching loop\n",
    "results = []\n",
    "for celltype in unique_celltypes:\n",
    "    celltype_lower = celltype.lower().strip()\n",
    "    if celltype_lower in SKIP_MATCHING_TERMS:\n",
    "        results.append({\n",
    "            \"original_celltype\": celltype,\n",
    "            \"query_used\": celltype,\n",
    "            \"matched_term\": celltype,\n",
    "            \"matched_field\": \"NA\",\n",
    "            \"CMT_ID\": None,\n",
    "            \"match_score\": None\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    query_term = MATCH_ANCHORS.get(celltype, celltype)\n",
    "\n",
    "    # Exact match check\n",
    "    matched_exact = None\n",
    "    for i, term in enumerate(all_terms):\n",
    "        if query_term.lower() == term.lower():\n",
    "            matched_exact = candidate_map[i]\n",
    "            score = 100\n",
    "            break\n",
    "\n",
    "    if matched_exact:\n",
    "        matched_term, matched_bmg_id, matched_field = matched_exact\n",
    "    else:\n",
    "        match, score, idx = process.extractOne(\n",
    "            query=query_term,\n",
    "            choices=all_terms,\n",
    "            scorer=fuzz.token_sort_ratio\n",
    "        )\n",
    "        matched_term, matched_bmg_id, matched_field = candidate_map[idx]\n",
    "\n",
    "    results.append({\n",
    "        \"original_celltype\": celltype,\n",
    "        \"query_used\": query_term,\n",
    "        \"matched_term\": matched_term,\n",
    "        \"matched_field\": matched_field,\n",
    "        \"CMT_ID\": matched_bmg_id,\n",
    "        \"match_score\": score\n",
    "    })\n",
    "\n",
    "# Separate review list (score != 100)\n",
    "review_list = [r for r in results if r.get(\"match_score\") != 100 and r.get(\"match_score\") is not None]\n",
    "review_list_sorted = sorted(review_list, key=lambda x: x[\"match_score\"], reverse=True)\n",
    "\n",
    "# Output directories\n",
    "os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)\n",
    "\n",
    "# Save full result\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Save review-needed subset\n",
    "with open(OUTPUT_REVIEW, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(review_list_sorted, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Summary report\n",
    "total = len([r for r in results if r.get(\"match_score\") is not None])\n",
    "exact = len([r for r in results if r.get(\"match_score\") == 100])\n",
    "print(f\"Exact matches: {exact} / {total} ({round(exact/total * 100, 2)}%)\")\n",
    "print(f\"Review-needed entries saved to: {OUTPUT_REVIEW}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1bc1e",
   "metadata": {},
   "source": [
    "## Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12f8753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped sex terms saved to: ./mapping_table/mapped_sex.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "INPUT_PATH = \"./field_uniques/sex_unique_values.csv\"\n",
    "OUTPUT_PATH = \"./mapping_table/mapped_sex.json\"\n",
    "\n",
    "# Manual mapping rules\n",
    "MAPPING = {\n",
    "    \"f\": \"female\",\n",
    "    \"m\": \"male\",\n",
    "    \"female\": \"female\",\n",
    "    \"male\": \"male\",\n",
    "    \"unknown\": \"unknown\",\n",
    "    \"unclassified\": \"unknown\",\n",
    "    \"nan\": \"unknown\",\n",
    "    \"\": \"unknown\"\n",
    "}\n",
    "\n",
    "# Load unique values\n",
    "df = pd.read_csv(INPUT_PATH, dtype=str).fillna(\"nan\")\n",
    "values = df[\"sex\"].tolist()\n",
    "\n",
    "# Process mapping\n",
    "results = []\n",
    "for value in values:\n",
    "    key = value.strip().lower()\n",
    "    mapped = MAPPING.get(key, \"unknown\")\n",
    "    results.append({\n",
    "        \"original_sex\": value,\n",
    "        \"normalized_sex\": mapped\n",
    "    })\n",
    "\n",
    "# Save JSON\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Mapped sex terms saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec7b87",
   "metadata": {},
   "source": [
    "## Development Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5d35b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All mapped development stages saved to: ./mapping_table/mapped_development_stages.json\n",
      "2 items needing review saved to: ./mapping_table/review_development_stages.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "INPUT_PATH = \"./field_uniques/development_stage_unique_values.csv\"\n",
    "OUTPUT_ALL = \"./mapping_table/mapped_development_stages.json\"\n",
    "OUTPUT_REVIEW = \"./mapping_table/review_development_stages.json\"\n",
    "\n",
    "# Carnegie stage: estimated days per stage from authoritative tables\n",
    "CARNEGIE_STAGE_DAYS = {\n",
    "    1: 1, 2: 2.5, 3: 4.5, 4: 5.5, 5: 9.5, 6: 14,\n",
    "    7: 16, 8: 18, 9: 20, 10: 22.5, 11: 24, 12: 28,\n",
    "    13: 31.5, 14: 33, 15: 36.5, 16: 39.5, 17: 43,\n",
    "    18: 46, 19: 49.5, 20: 51.5, 21: 54, 22: 55, 23: 61.5\n",
    "}\n",
    "\n",
    "# Named stages directly mapped\n",
    "NAMED_STAGE_MAPPING = {\n",
    "    \"adult stage\": (30, \"adult\"),\n",
    "    \"young adult stage\": (20, \"young adult\"),\n",
    "    \"prime adult stage\": (35, \"adult\"),\n",
    "    \"middle aged stage\": (50, \"middle aged\"),\n",
    "    \"late adult stage\": (70, \"aged\"),\n",
    "    \"infant stage\": (0.5, \"infant\"),\n",
    "    \"child stage (1-4 yo)\": (2.5, \"preschool child\"),\n",
    "    \"juvenile stage (5-14 yo)\": (9.5, \"child\"),\n",
    "    \"pediatric stage\": (10, \"child\"),\n",
    "    \"postnatal stage\": (0.1, \"infant\"),\n",
    "    \"blastula stage\": (0.01, \"embryonic\"),\n",
    "    \"embryonic stage\": (0.03, \"embryonic\"),\n",
    "    \"organogenesis stage\": (0.05, \"embryonic\"),\n",
    "    \"unknown\": (None, \"unknown\"),\n",
    "}\n",
    "\n",
    "# MeSH-based age category mapping\n",
    "def age_category(age):\n",
    "    if age is None:\n",
    "        return \"unknown\"\n",
    "    if age < 0.08:\n",
    "        return \"newborn\"\n",
    "    if age < 1:\n",
    "        return \"infant\"\n",
    "    if age < 6:\n",
    "        return \"preschool child\"\n",
    "    if age < 13:\n",
    "        return \"child\"\n",
    "    if age < 19:\n",
    "        return \"adolescent\"\n",
    "    if age < 25:\n",
    "        return \"young adult\"\n",
    "    if age < 45:\n",
    "        return \"adult\"\n",
    "    if age < 65:\n",
    "        return \"middle aged\"\n",
    "    if age < 80:\n",
    "        return \"aged\"\n",
    "    return \"80 and over\"\n",
    "\n",
    "# Extract numeric age from free-text terms\n",
    "def parse_numeric_age(term):\n",
    "    term = term.lower().strip()\n",
    "\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*yr', term)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*year', term)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*-year-old', term)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*(?:mo|month)', term)\n",
    "    if match:\n",
    "        return round(float(match.group(1)) / 12, 2)\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*-month-old', term)\n",
    "    if match:\n",
    "        return round(float(match.group(1)) / 12, 2)\n",
    "\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*(?:w|week)', term)\n",
    "    if match:\n",
    "        return round(float(match.group(1)) / 52, 2)\n",
    "    match = re.search(r'(\\d+)(?:st|nd|rd|th) week post-fertilization', term)\n",
    "    if match:\n",
    "        return round(float(match.group(1)) / 52, 2)\n",
    "\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*d', term)\n",
    "    if match:\n",
    "        return round(float(match.group(1)) / 365, 3)\n",
    "\n",
    "    match = re.search(r'carnegie stage\\s*(\\d+)', term)\n",
    "    if match:\n",
    "        stage = int(match.group(1))\n",
    "        if stage in CARNEGIE_STAGE_DAYS:\n",
    "            return round(CARNEGIE_STAGE_DAYS[stage] / 365, 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "# Handle named stages and fallback parsing\n",
    "def parse_named_stage(term):\n",
    "    if term in NAMED_STAGE_MAPPING:\n",
    "        return NAMED_STAGE_MAPPING[term]\n",
    "\n",
    "    match = re.match(r'(\\w+)\\s+decade stage', term)\n",
    "    if match:\n",
    "        word_to_decade = {\n",
    "            \"third\": 30, \"fourth\": 40, \"fifth\": 50,\n",
    "            \"sixth\": 60, \"seventh\": 70, \"eighth\": 80, \"ninth\": 90\n",
    "        }\n",
    "        dec = match.group(1).lower()\n",
    "        if dec in word_to_decade:\n",
    "            age = word_to_decade[dec] + 5\n",
    "            return (age, age_category(age))\n",
    "\n",
    "    match = re.match(r'(\\w+)\\s+LMP month stage', term)\n",
    "    if match:\n",
    "        word_to_month = {\n",
    "            \"first\": 1, \"second\": 2, \"third\": 3, \"fourth\": 4,\n",
    "            \"fifth\": 5, \"sixth\": 6, \"seventh\": 7, \"eighth\": 8, \"ninth\": 9\n",
    "        }\n",
    "        month = match.group(1).lower()\n",
    "        if month in word_to_month:\n",
    "            gest_weeks = (word_to_month[month] - 0.5) * 4\n",
    "            return (round(gest_weeks / 52, 2), \"fetal\")\n",
    "\n",
    "    fallback_age = parse_numeric_age(term)\n",
    "    if fallback_age is not None:\n",
    "        return fallback_age, age_category(fallback_age)\n",
    "\n",
    "    return None, \"unknown\"\n",
    "\n",
    "# Process and categorize development stages\n",
    "df = pd.read_csv(INPUT_PATH, dtype=str).fillna(\"\")\n",
    "terms = df[\"development_stage\"].unique().tolist()\n",
    "\n",
    "all_results = []\n",
    "review_list = []\n",
    "\n",
    "for term in terms:\n",
    "    numeric_age = parse_numeric_age(term)\n",
    "    if numeric_age is not None:\n",
    "        category = age_category(numeric_age)\n",
    "    else:\n",
    "        numeric_age, category = parse_named_stage(term)\n",
    "\n",
    "    if category in {\"fetal\", \"embryonic\"}:\n",
    "        phase = \"pre-birth\"\n",
    "    elif category == \"unknown\":\n",
    "        phase = \"unknown\"\n",
    "    else:\n",
    "        phase = \"post-birth\"\n",
    "\n",
    "    result = {\n",
    "        \"original_stage\": term,\n",
    "        \"numeric_age\": numeric_age,\n",
    "        \"age_category\": category,\n",
    "        \"birth_phase\": phase\n",
    "    }\n",
    "    all_results.append(result)\n",
    "\n",
    "    if numeric_age is None:\n",
    "        review_list.append(result)\n",
    "\n",
    "# Output results\n",
    "os.makedirs(os.path.dirname(OUTPUT_ALL), exist_ok=True)\n",
    "with open(OUTPUT_ALL, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(OUTPUT_REVIEW, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(review_list, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"All mapped development stages saved to: {OUTPUT_ALL}\")\n",
    "print(f\"{len(review_list)} items needing review saved to: {OUTPUT_REVIEW}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee2f7e1",
   "metadata": {},
   "source": [
    "## DB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7199476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced metadata saved to: ./cell_metadata_with_mappings.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# File paths\n",
    "metadata_path = \"./cell_metadata.parquet\"\n",
    "celltype_map_path = \"./mapping_table/mapped_celltypes.json\"\n",
    "disease_map_path = \"./mapping_table/mapped_diseases.json\"\n",
    "dev_stage_map_path = \"./mapping_table/mapped_development_stages.json\"\n",
    "sex_map_path = \"./mapping_table/mapped_sex.json\"\n",
    "output_path = \"./cell_metadata_with_mappings.parquet\"\n",
    "\n",
    "# Load metadata\n",
    "df = pd.read_parquet(metadata_path)\n",
    "\n",
    "# Load mapping files\n",
    "with open(celltype_map_path, encoding=\"utf-8\") as f:\n",
    "    celltype_map = {x[\"original_celltype\"]: x for x in json.load(f)}\n",
    "\n",
    "with open(disease_map_path, encoding=\"utf-8\") as f:\n",
    "    disease_map = {x[\"original_disease\"]: x for x in json.load(f)}\n",
    "\n",
    "with open(dev_stage_map_path, encoding=\"utf-8\") as f:\n",
    "    dev_map = {x[\"original_stage\"]: x for x in json.load(f)}\n",
    "\n",
    "with open(sex_map_path, encoding=\"utf-8\") as f:\n",
    "    sex_map = {x[\"original_sex\"]: x for x in json.load(f)}\n",
    "\n",
    "# Mapping helpers\n",
    "def get_bmg_fields(map_dict, value):\n",
    "    entry = map_dict.get(value, {})\n",
    "    bmg_id = entry.get(\"BioMedGraphica_ID\", \"\")\n",
    "    bmg_name = entry.get(\"matched_term\", \"\")\n",
    "    if not bmg_id or bmg_id == \"null\":\n",
    "        bmg_id = \"\"\n",
    "    if not bmg_name or bmg_name == \"null\":\n",
    "        bmg_name = \"\"\n",
    "    return bmg_id, bmg_name\n",
    "\n",
    "def get_cmt_fields(map_dict, value):\n",
    "    entry = map_dict.get(value, {})\n",
    "    bmg_id = entry.get(\"CMT_ID\", \"\")\n",
    "    bmg_name = entry.get(\"matched_term\", \"\")\n",
    "    if not bmg_id or bmg_id == \"null\":\n",
    "        bmg_id = \"\"\n",
    "    if not bmg_name or bmg_name == \"null\":\n",
    "        bmg_name = \"\"\n",
    "    return bmg_id, bmg_name\n",
    "\n",
    "def get_dev_fields(map_dict, value):\n",
    "    entry = map_dict.get(value, {})\n",
    "    return (\n",
    "        entry.get(\"numeric_age\", None),\n",
    "        entry.get(\"age_category\", \"\"),\n",
    "        entry.get(\"birth_phase\", \"\")\n",
    "    )\n",
    "\n",
    "def get_sex_field(map_dict, value):\n",
    "    entry = map_dict.get(value, {})\n",
    "    return entry.get(\"normalized_sex\", \"\")\n",
    "\n",
    "# Add mapped columns\n",
    "df[\"CMT_id\"], df[\"CMT_name\"] = zip(*df[\"cell_type\"].map(lambda v: get_cmt_fields(celltype_map, v)))\n",
    "df[\"disease_BMG_id\"], df[\"disease_BMG_name\"] = zip(*df[\"disease\"].map(lambda v: get_bmg_fields(disease_map, v)))\n",
    "df[\"development_stage_numeric_age\"], df[\"development_stage_category\"], df[\"birth_phase\"] = zip(*df[\"development_stage\"].map(lambda v: get_dev_fields(dev_map, v)))\n",
    "df[\"sex_normalized\"] = df[\"sex\"].map(lambda v: get_sex_field(sex_map, v))\n",
    "\n",
    "if \"tissue_general\" in df.columns:\n",
    "    df[\"tissue_general\"] = df[\"tissue_general\"].astype(str).str.replace(\"_\", \" \")\n",
    "\n",
    "# Save to file\n",
    "df.to_parquet(output_path, index=False)\n",
    "df.to_csv(\"./cell_metadata_with_mappings.csv\", index=False)\n",
    "print(f\"Enhanced metadata saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "win_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
