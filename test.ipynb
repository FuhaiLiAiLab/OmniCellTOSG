{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 483817) (291,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x_file_path = './CellTOG/brain_sc_output/processed_data/brain/alzheimer\\'s_disease/alzheimer\\'s_disease_X_partition_0.npy'\n",
    "y_file_path = './CellTOG/brain_sc_output/processed_data/brain/alzheimer\\'s_disease/alzheimer\\'s_disease_Y_partition_0.npy'\n",
    "\n",
    "x = np.load(x_file_path)\n",
    "y = np.load(y_file_path)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 33349084) (483817, 1)\n",
      "[[     0      1      2 ... 483091 483091 483091]\n",
      " [278326 278327 278328 ... 386373 398848 437378]]\n"
     ]
    }
   ],
   "source": [
    "edge_index_path = './CellTOG/brain_sc_output/edge_index.npy'\n",
    "x_desc_path = './CellTOG/brain_sc_output/X_descriptions.npy'\n",
    "\n",
    "edge_index = np.load(edge_index_path)\n",
    "x_desc = np.load(x_desc_path, allow_pickle=True)\n",
    "print(edge_index.shape, x_desc.shape)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADP ribosylation factor 5 [Source:HGNC Symbol;Acc:HGNC:658]'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_desc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert x_desc to list of strings\n",
    "x_desc = [str(i) for i in x_desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['ADP ribosylation factor 5 [Source:HGNC Symbol;Acc:HGNC:658]']\",\n",
       " \"['mannose-6-phosphate receptor, cation dependent [Source:HGNC Symbol;Acc:HGNC:6752]']\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_desc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483817,)\n",
      "(278326,) (205491,)\n"
     ]
    }
   ],
   "source": [
    "transcript_name_emb_path = './BioMedGraphica/embeddings/Entity/transcript_embeddings.npy'\n",
    "protein_name_emb_path = './BioMedGraphica/embeddings/Entity/protein_embeddings.npy'\n",
    "\n",
    "transcript_name_emb = np.load(transcript_name_emb_path)\n",
    "protein_name_emb = np.load(protein_name_emb_path)\n",
    "name_emb = np.concatenate((transcript_name_emb, protein_name_emb), axis=0)\n",
    "print(name_emb.shape)\n",
    "print(transcript_name_emb.shape, protein_name_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desc emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, sentences: List[str]):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imhem\\anaconda3\\envs\\mkg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import List, Tuple, Dict\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pykeen.training.callbacks import TrainingCallback  # Updated base class for callbacks\n",
    "\n",
    "from pykeen.models import TransR\n",
    "from pykeen.training import SLCWATrainingLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmb():\n",
    "    def __init__(self, model_path: str = \"microsoft/deberta-v3-small\", device: str = \"cuda\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_path (str, optional): Path to the deberta model. Defaults to 'microsoft/deberta-v3-small'.\n",
    "            device (str, optional): Device to run the model on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Load the deberta model and tokenizer from the specified model path.\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "        self.model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "\n",
    "    def generate_embeddings(self, sentences: List[str], batch_size: int = 32, text_emb_dim: int = 64) -> List[float]:\n",
    "        \"\"\"\n",
    "        Generate a single-dimensional embedding for each sentence.\n",
    "\n",
    "        Args:\n",
    "            sentences (List[str]): List of sentences to embed.\n",
    "            batch_size (int, optional): Batch size for DataLoader. Defaults to 32.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: List of single-dimensional embeddings.\n",
    "        \"\"\"\n",
    "        dataset = SentenceDataset(sentences)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        embeddings = []\n",
    "        for batch in tqdm(dataloader, desc=\"Embedding sentences\", unit=\"batch\"):\n",
    "            inputs = self.tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            batch_embeddings = torch.mean(outputs.last_hidden_state, dim=1).squeeze().cpu()\n",
    "            # Adaptive pooling to 64 dimensions (pooling over the hidden dimension)\n",
    "            projected = torch.nn.functional.adaptive_avg_pool1d(batch_embeddings.unsqueeze(1), output_size=text_emb_dim).squeeze(1)\n",
    "            embeddings.extend(projected.tolist())\n",
    "        return embeddings\n",
    "\n",
    "    def save_embeddings(self, embeddings: List[float], ids: List[str], output_npy_path: str, output_csv_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Save embeddings to a .npy file and IDs to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            embeddings (List[float]): List of single-dimensional embeddings.\n",
    "            ids (List[str]): List of corresponding IDs.\n",
    "            output_npy_path (str): Path to save the .npy file.\n",
    "            output_csv_path (str): Path to save the index CSV file.\n",
    "        \"\"\"\n",
    "        # Save the embeddings to .npy file\n",
    "        np.save(output_npy_path, np.array(embeddings))\n",
    "        print(f\"Embeddings saved at {output_npy_path} with shape {np.array(embeddings).shape}\")\n",
    "\n",
    "        # Save the IDs to CSV\n",
    "        index_df = pd.DataFrame(ids, columns=[\"biomedgraphica_id\"])\n",
    "        index_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    def process_data_and_generate_embeddings(self, sentences: List, batch_size: str, text_emb_dim: int) -> Tuple[List[float], List[str]]:\n",
    "\n",
    "        embeddings = self.generate_embeddings(sentences, batch_size, text_emb_dim)\n",
    "        # print generated embeddings at shape\n",
    "        print(f\"Generated embeddings at shape {np.array(embeddings).shape}\")\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imhem\\AppData\\Local\\Temp\\ipykernel_30944\\473054218.py:1: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mapping_table = pd.read_csv('./CellTOG/brain_sc_output/mapping_table.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_index</th>\n",
       "      <th>BioMedGraphica_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>ARF5</td>\n",
       "      <td>BMG_TS000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M6PR</td>\n",
       "      <td>M6PR</td>\n",
       "      <td>BMG_TS000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ESRRA</td>\n",
       "      <td>ESRRA</td>\n",
       "      <td>BMG_TS000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FKBP4</td>\n",
       "      <td>FKBP4</td>\n",
       "      <td>BMG_TS000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BMG_TS000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index original_id original_index BioMedGraphica_ID\n",
       "0      0        ARF5           ARF5      BMG_TS000001\n",
       "1      1        M6PR           M6PR      BMG_TS000002\n",
       "2      2       ESRRA          ESRRA      BMG_TS000003\n",
       "3      3       FKBP4          FKBP4      BMG_TS000004\n",
       "4      4         NaN            NaN      BMG_TS000005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483817\n",
      "['BMG_TS000001', 'BMG_TS000002']\n"
     ]
    }
   ],
   "source": [
    "mapping_table = pd.read_csv('./CellTOG/brain_sc_output/mapping_table.csv')\n",
    "display(mapping_table.head())\n",
    "ids = mapping_table['BioMedGraphica_ID'].tolist()\n",
    "print(len(ids))\n",
    "print(ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"microsoft/deberta-v3-small\"\n",
    "device = \"cuda\"\n",
    "batch_size = 128\n",
    "desc_emb_dim = 1\n",
    "output_npy_path = \"./CellTOG/x_desc_emb.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imhem\\anaconda3\\envs\\mkg\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder = TextEmb(model_path, device)\n",
    "encoder.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.process_data_and_generate_embeddings(x_desc, batch_size, desc_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq emb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
